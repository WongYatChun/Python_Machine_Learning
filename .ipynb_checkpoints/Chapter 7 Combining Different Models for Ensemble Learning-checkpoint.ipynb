{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03432750701904297"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Chapter focus:\n",
    "#1. Make predictions based on majority voting\n",
    "#2. Use bagging the reduce overfitting by drawing random combinations of the training set with repetition\n",
    "#3. Apply boosting to build powerful models from weak learners that learn from their mistakes\n",
    "\n",
    "#Ensemble methods:\n",
    "#-Combine different classifiers into a meta-classifier that has better generalization performance\n",
    "#-Most popular: majority voting\n",
    "# -> select the class label that has been predicted by the majority of classifiers\n",
    "# -> Binary class settings only\n",
    "# -> Multi-class settings? Plurality voting\n",
    "#-Techniques:\n",
    "# -> build from different classification algorithms\n",
    "# -> use the same base classification algorithm, fitting different subsets of the training set\n",
    "#-Why ensemble methods can work better than individual classifiers?\n",
    "# -> the error probability of an ensemble of base classifiers is a probability mass function of a binomial distribution\n",
    "# -> if many people say yes, then probably it is more true than a single person says yes.\n",
    "\n",
    "#Compare an idealistic ensemble classifier to a base classifier over a range of different base error rates\n",
    "\n",
    "from scipy.special import comb\n",
    "import math\n",
    "\n",
    "#implement the ensemble_error function\n",
    "def ensemble_error(n_classifier,error):\n",
    "    k_start = int(math.ceil(n_classifier/2.))\n",
    "    probs = [comb(n_classifier,k)*error**k*(1-error)**(n_classifier-k)\n",
    "             for k in range(k_start,n_classifier+1)]\n",
    "    return sum(probs)\n",
    "\n",
    "#Test\n",
    "ensemble_error(n_classifier=11,error=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualize the relationship between ensemble and base errors in a line graph\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "error_range = np.arange(0.0,1.01,0.01)\n",
    "ens_errors = [ensemble_error(n_classifier=11,error=error)\n",
    "              for error in error_range]\n",
    "\n",
    "#Plot the line of ensemble errors\n",
    "plt.plot(error_range,ens_errors,label='Ensemble error',linewidth=2)\n",
    "\n",
    "#Plot the line of base error\n",
    "plt.plot(error_range,error_range,linestyle='--',label='Base error',linewidth=2)\n",
    "\n",
    "#Legend stuff\n",
    "plt.xlabel('Base error')\n",
    "plt.ylabel('Base/Ensemble error')\n",
    "plt.legend(loc='upper left')\n",
    "plt.grid(alpha=0.5)\n",
    "plt.show()\n",
    "\n",
    "#As long as the base classifiers perform better than random guessing (error rate < 0.5)\n",
    "#Ensemble always performs better than individual base classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Combining classifiers via majority vote\n",
    "\n",
    "#Implementing a simple majority vote classifier\n",
    "#Combine different classification algorithms associated with individual weights for confidence\n",
    "#Goal: build a stronger meta-classifier that balances out the individual classifiers' weaknesses on a particular dataset\n",
    "\n",
    "#Illustration of the weighted majority vote:\n",
    "np.argmax(np.bincount([0,0,1],weights=[0.2,0.2,0.6]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.58, 0.42])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Illustration of the weighted majority vote based on class probability\n",
    "\n",
    "ex = np.array([[0.9,0.1],\n",
    "               [0.8,0.2],\n",
    "               [0.4,0.6]])\n",
    "p = np.average(ex,axis=0,weights=[.2,.2,.6])\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator #inherit some base functionalities\n",
    "from sklearn.base import ClassifierMixin #inherit some base functionalities\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.externals import six #make the class compatible with Python 2.6\n",
    "from sklearn.base import clone\n",
    "from sklearn.pipeline import _name_estimators\n",
    "import numpy as np\n",
    "import operator\n",
    "\n",
    "class MajorityVoteClassifier(BaseEstimator,ClassifierMixin): #inheritance\n",
    "    \"\"\"A Majority Vote Ensemble Classifier\n",
    "    \n",
    "    Parameters\n",
    "    ------------\n",
    "    classifiers: array-like, shape = [n_classifiers]\n",
    "        Different classifiers for the ensemble\n",
    "        \n",
    "    vote: str, {'classlabel','probability'}(default='label')\n",
    "        If 'classlabel' the prediction is based on the armax of class labels.\n",
    "        Else if 'probability', the argmax of sum of probabilities is used to predict the class label\n",
    "        (recommended for calibrated classifiers).\n",
    "        \n",
    "    weights: array-like, shape = [n_classifiers], optional (default = None)\n",
    "        If a list of `int` or `float` values are provided, the classifiers\n",
    "        are weighted by importance; Uses uniform weights if `weights=None\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,classifiers,vote='classlabel',weights=None):\n",
    "        self.classifiers = classifiers\n",
    "        self.named_classifiers={key:value \n",
    "                                for key, value in _name_estimators(classifiers)}\n",
    "        self.vote = vote\n",
    "        self.weights = weights\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        \"\"\"Fit classifiers.\n",
    "        \n",
    "        Parameters\n",
    "        ------------------\n",
    "        X:{array-like, sparse matrix}, shape=[n_samples,n_features]\n",
    "            Matrix of training samples\n",
    "            \n",
    "        y: array-like, shape=[n_samples]\n",
    "            Vector of target class labels\n",
    "            \n",
    "        Returns\n",
    "        ----------------\n",
    "        self: object\n",
    "        \"\"\"\n",
    "        #Exception handling\n",
    "        if self.vote not in ('probability','classlabel'):\n",
    "            raise ValueError(\"vote must be 'probability' or 'classlabel'\"\n",
    "                             \"; got (vote=%r)\" % self.vote)\n",
    "        if self.weights and len(self.weights) != len(self.classifiers):\n",
    "            raise ValueError('NUmber of classifiers and weight must be equal;'\n",
    "                             'got %d weights, %d classifiers'\n",
    "                             % (len(self.weights),len(self.classifiers)))\n",
    "        \n",
    "        #Use LabelEncoder to ensure class labels start with 0, which\n",
    "        #is important for np.argmax call in self.predict\n",
    "        self.labelenc_=LabelEncoder()\n",
    "        self.labelenc_.fit(y)\n",
    "        self.classes_ = self.labelenc_.classes_\n",
    "        self.classifiers_ = []\n",
    "        \n",
    "        #fit the training sets with different classifiers\n",
    "        for clf in self.classifiers:\n",
    "            fitted_clf = clone(clf).fit(X,self.labelenc_.transform(y)) #without clone, maybe only return data not a classifier???\n",
    "            self.classifiers_.append(fitted_clf)\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def predict(self,X):\n",
    "        \"\"\"Predict class labels for X.\n",
    "        \n",
    "        Parameters\n",
    "        -----------\n",
    "        X: {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
    "        \n",
    "        Returns\n",
    "        -----------\n",
    "        maj_vote: array-like, shape = [n_samples]\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        if self == 'probability':\n",
    "            maj_vote = np.argmax(self.predict_proba(X),axis=1)\n",
    "        else: # 'classlabel' vote\n",
    "            # Collect results from clf.predict calls\n",
    "            predictions = np.asarray([clf.predict(X) #asarray convert structured data into an ndarray\n",
    "                                      for clf in self.classifiers_]).T #noted that it is transposed\n",
    "            #Apply the lambda function along the column\n",
    "            #each column stands for each sample, \n",
    "            #lambda function find the weighted mode of the prediction\n",
    "            #as a result, each sample has a major_vote result\n",
    "            \n",
    "            maj_vote = np.apply_along_axis(lambda x: np.argmax(np.bincount(x,weights=self.weights)),\n",
    "                                          axis=1,arr=predictions)\n",
    "        #convert the labelencoded code back to labels\n",
    "        maj_vote = self.labelenc_.inverse_transform(maj_vote)\n",
    "        \n",
    "        return maj_vote\n",
    "        \n",
    "    def predict_proba(self,X):\n",
    "        \"\"\"Predict class probabilities for X\n",
    "        \n",
    "        Parameters\n",
    "        -----------\n",
    "        X: {array-like, sparse matrix}, shape=[n_samples, n_features]\n",
    "            Training vectors, where n_samples is the number of samples and n_features i the number of features.\n",
    "            \n",
    "        Returns\n",
    "        -----------\n",
    "        avg.proba: array-like, shape=[n_samples, n_classes]\n",
    "            Weighted averge probability for each class per sample.\n",
    "        \"\"\"\n",
    "        #Calculate the proba for each label in each sample\n",
    "        probas = np.asarray([clf.predict_proba(X)\n",
    "                             for clf in self.classifiers_]) #no transpose\n",
    "        #column: prob each label, row: prob\n",
    "        #apply to row, get\n",
    "        avg_proba = np.average(probas, axis=0, weights=self.weights)\n",
    "        return avg_proba\n",
    "    \n",
    "    def get_params(self,deep=True):\n",
    "        \"\"\"Get classifier parameter names for GridSearch\"\"\"\n",
    "        if not deep:\n",
    "            return super(MajorityVoteClassifier,self).get_params(get_params=False)\n",
    "        else:\n",
    "            out = self.named_classifiers.copy()\n",
    "            for name, step in six.iteritems(self.named_classifiers):\n",
    "                for key, value in six.iteriterms(step.get_params(deep=True)):\n",
    "                    out['%s__%s' % (name,key)] = value\n",
    "            return out\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the majority voting principle to make predictions\n",
    "\n",
    "#load the Iris dataset from scikit-learn's dataset module\n",
    "#only select two features, sepal width and petal length \n",
    "#to make the classification task more challenging for illustration purpose\n",
    "\n",
    "#Although MajorityVoteClassifier generalises to multiclass problems,\n",
    "#we will only classify flower samples from the Iris-versicolor and Iris-virginica classes\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#load the data\n",
    "iris = datasets.load_iris()\n",
    "#only classify flower samples from the Iris-versicolor and Iris-virginica classes\n",
    "#only select two features, sepal width and petal length \n",
    "X,y = iris.data[50:,[1,2]],iris.target[50:]\n",
    "#encode the label\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "#split the Iris samples into 50% training and 50% test data\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X,y,test_size=0.5,random_state=1,stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-9-cae61fdfd4be>, line 26)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-cae61fdfd4be>\"\u001b[0;36m, line \u001b[0;32m26\u001b[0m\n\u001b[0;31m    for clf, label in zip([pipe1,clf2,pipe3],clf_labels):\u001b[0m\n\u001b[0m                                                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "#Train 3 different classifiers:\n",
    "#1. Logistic regression classifier\n",
    "#2. Decision tree classifier\n",
    "#3. k-nearest neighbors classifier\n",
    "\n",
    "#evaluate the performance of each classifier via 10-fold cross-validation on the training dataset\n",
    "#before combining them in to an ensemble classifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import numpy as np\n",
    "clf1 = LogisticRegression(penalty='l2',C=0.001,random_state=1)\n",
    "clf2 = DecisionTreeClassifier(max_depth=1,criterion='entropy',random_state=0)\n",
    "clf3 = KNeighborsClassifier(n_neighbors=1,p=2,metric='minkowski')\n",
    "\n",
    "pipe1 = Pipeline([['sc',StandardScaler()],['clf',clf1]])\n",
    "pipe3 = Pipeline([['sc',StandardScaler()],['clf',clf3]])\n",
    "\n",
    "clf_labels = ['Logistic regression','Decision tree','KNN']\n",
    "\n",
    "print('10-fold cross validation: \\n')\n",
    "for clf, label in zip([pipe1,clf2,pipe3],clf_labels):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
