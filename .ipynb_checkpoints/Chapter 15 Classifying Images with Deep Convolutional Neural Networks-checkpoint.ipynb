{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 15 - Classifying Images with Deep Convolutional Neural Networks\n",
    "\n",
    "\n",
    "- Understanding convolutional operations in one and two dimensions\n",
    "- Learning about the building blocks of CNN architectures\n",
    "- Implementing deep convolutional neural networks in TensorFlow\n",
    "\n",
    "Key to the performance of any machine learning algorithm\n",
    "- extractung salient features\n",
    "    - Traditional: rely on input features that may come from a domain expert, or are based on computational feature extraction techniques\n",
    "    - Neural networks: automatically learn the features from new raw data that are most useful for a particular task.\n",
    "        - a feature extraction engine: the early layers extract low-level features\n",
    "        - Multilayer neural networks: feature hierachy\n",
    "            - combining the low-level features in a layer-wise fashion to form high-level features\n",
    "            \n",
    "Local receptive field: local patch of pixels\n",
    "\n",
    "CNN will usually perform very well for image-related tasks, because:\n",
    "1. Sparse-connectivity: a single element in the feature map is connected to only a small patch of pixels\n",
    "2. Parameter-sharing: The same weights are used for different patches of the input image\n",
    "\n",
    "As a direct consequence, the number of weights(parameters) in the network decreases dramatically, and we see an improvement in the ability to capture salient features.\n",
    "\n",
    "Intuitively, nearby pixels are probably more relevant to each other than pixels that are far away each other.\n",
    "\n",
    "Typically, CNNs are composed of    \n",
    "\n",
    "1. several **Convoluntional(conv)** layers\n",
    "    - with learnable parameters, e.g. weights or bias units\n",
    "\n",
    "\n",
    "2. several subsampling (also known as **Pooling(P)**) layers\n",
    "    - no any learnable parameters, no weights or bias units\n",
    "\n",
    "\n",
    "3. **Fully Connected (PC)** layers\n",
    "    - with learnable parameters, e.g. weights or bias units\n",
    "    - essentially a multilayer perceptron\n",
    "    - every input unit i is connected to every output unit j with weight $w_{ij}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
