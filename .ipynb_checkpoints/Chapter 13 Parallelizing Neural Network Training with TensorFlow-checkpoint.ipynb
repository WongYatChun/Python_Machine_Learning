{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is TensorFlow?\n",
    "\n",
    "### First steps with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x= 1.0 --> z= 2.7\n",
      "x= 0.6 --> z= 1.9\n",
      "x=-1.8 --> z=-2.9\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "## create a graph\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    x = tf.placeholder(dtype=tf.float32,\n",
    "                       shape=(None), name='x')\n",
    "    w = tf.Variable(2.0, name='weight')\n",
    "    b = tf.Variable(0.7, name='bias')\n",
    "\n",
    "    z = w*x + b\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "## create a session and pass in graph g\n",
    "with tf.Session(graph=g) as sess:\n",
    "    ## initialize w and b:\n",
    "    sess.run(init)\n",
    "    ## evaluate z:\n",
    "    for t in [1.0, 0.6, -1.8]:\n",
    "        print('x=%4.1f --> z=%4.1f'%(\n",
    "              t, sess.run(z, feed_dict={x:t})))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.7 4.7 6.7]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph = g) as sess:\n",
    "    sess.run(init)\n",
    "    print(sess.run(z,feed_dict={x:[1.,2.,3.]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with array structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape:  (3, 2, 3)\n",
      "Reshaped: \n",
      " [[ 0.  1.  2.  3.  4.  5.]\n",
      " [ 6.  7.  8.  9. 10. 11.]\n",
      " [12. 13. 14. 15. 16. 17.]]\n",
      "Column Sums: \n",
      " [18. 21. 24. 27. 30. 33.]\n",
      "Column Means: \n",
      " [ 6.  7.  8.  9. 10. 11.]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "g = tf.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "    x = tf.placeholder(dtype = tf.float32,\n",
    "                       shape = (None, 2, 3),\n",
    "                       name = 'input_x')\n",
    "    x2 = tf.reshape(x, shape = (-1, 6),# we dont know the batch size\n",
    "                                       # used to flatten a tensor\n",
    "                    name = 'x2')\n",
    "    \n",
    "    ## calculate the sum of each column\n",
    "    xsum = tf.reduce_sum(x2, axis = 0, name = 'col_sum')\n",
    "    \n",
    "    ## calculate the mean of the column\n",
    "    xmean = tf.reduce_mean(x2, axis = 0, name = 'col_mean')\n",
    "    \n",
    "with tf.Session(graph = g) as sess:\n",
    "    x_array = np.arange(18).reshape(3,2,3)\n",
    "    print('input shape: ', x_array.shape)\n",
    "    print('Reshaped: \\n',\n",
    "          sess.run(x2, feed_dict = {x: x_array}))\n",
    "    print('Column Sums: \\n',\n",
    "          sess.run(xsum, feed_dict = {x: x_array}))\n",
    "    print('Column Means: \\n',\n",
    "          sess.run(xmean, feed_dict = {x: x_array}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Developong a simple model with low-level TensorFlow API\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "X_train = np.arange(10).reshape((10,1))\n",
    "y_train = np.array([1.0, 1.3, 3.1,\n",
    "                    2.0, 5.0, 6.3,\n",
    "                    6.6, 7.4, 8.0,\n",
    "                    9.0])\n",
    "\n",
    "class TfLinreg(object):\n",
    "    def __init__(self, x_dim, learning_rate = 0.01,\n",
    "                 random_seed = None):\n",
    "        self.x_dim = x_dim\n",
    "        self.learning_rate = learning_rate\n",
    "        self.g = tf.Graph()\n",
    "        ## Build the model\n",
    "        with self.g.as_default():\n",
    "            ## set graph-level random-seed\n",
    "            tf.set_random_seed(random_seed)\n",
    "            \n",
    "            self.build()\n",
    "            ## create initializer\n",
    "            self.init_op = tf.global_variables_initializer()\n",
    "    \n",
    "    def build(self):\n",
    "        ## define placeholders for inputs\n",
    "        self.X = tf.placeholder(dtype = tf.float32,\n",
    "                                shape = (None, self.x_dim),\n",
    "                                name = 'x_input')\n",
    "        self.y = tf.placeholder(dtype = tf.float32,\n",
    "                                shape = (None),\n",
    "                                name = 'y_input')\n",
    "        \n",
    "        print(self.X)\n",
    "        print(self.y)\n",
    "        \n",
    "        ## define weight matrix and bias vector\n",
    "        w = tf.Variable(tf.zeros(shape = (1)),\n",
    "                        name = 'weight')\n",
    "        b = tf.Variable(tf.zeros(shape = (1)),\n",
    "                        name = 'bias')\n",
    "        \n",
    "        print(w)\n",
    "        print(b)\n",
    "        \n",
    "        self.z_net = tf.squeeze(w * self.X + b,\n",
    "                                name = 'z_net')\n",
    "        print(self.z_net)\n",
    "        \n",
    "        sqr_errors = tf.square(self.y - self.z_net,\n",
    "                               name = 'sqr_errors')\n",
    "        print(sqr_errors)\n",
    "        # cost function to be MSE\n",
    "        self.mean_cost =tf.reduce_mean(sqr_errors,\n",
    "                                       name = 'mean_cost')\n",
    "        optimizer = tf.train.GradientDescentOptimizer(\n",
    "                    learning_rate = self.learning_rate,\n",
    "                    name = 'GradientDescent')\n",
    "        self.optimizer = optimizer.minimize(self.mean_cost)\n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"x_input:0\", shape=(?, 1), dtype=float32)\n",
      "Tensor(\"y_input:0\", dtype=float32)\n",
      "<tf.Variable 'weight:0' shape=(1,) dtype=float32_ref>\n",
      "<tf.Variable 'bias:0' shape=(1,) dtype=float32_ref>\n",
      "Tensor(\"z_net:0\", dtype=float32)\n",
      "Tensor(\"sqr_errors:0\", dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Create an instance this class\n",
    "\n",
    "lrmodel = TfLinreg(x_dim = X_train.shape[1], learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_linreg(sess, model, X_train, y_train, num_epochs = 10):\n",
    "    ## initialize all variables: W & b\n",
    "    sess.run(model.init_op)\n",
    "    \n",
    "    training_costs = []\n",
    "    for i in range(num_epochs):\n",
    "        _, cost = sess.run([model.optimizer, model.mean_cost],\n",
    "                            feed_dict = {model.X : X_train,\n",
    "                                         model.y : y_train})\n",
    "        training_costs.append(cost)\n",
    "        \n",
    "    return training_costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session(graph = lrmodel.g)\n",
    "training_costs = train_linreg(sess, lrmodel, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(1,len(training_costs)+1), training_costs)\n",
    "plt.tight_layout()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Training Cost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_linreg(sess, model, X_test):\n",
    "    y_pred = sess.run(model.z_net, feed_dict = {model.X:X_test})\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X_train, y_train,\n",
    "            marker = 's', s = 50,\n",
    "            label = 'Training Data')\n",
    "plt.plot(range(X_train.shape[0]),\n",
    "         predict_linreg(sess, lrmodel, X_train),\n",
    "         color = 'gray', marker = 'o',\n",
    "         markersize = 6, linewidth = 3,\n",
    "         label = 'LinReg Model')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training neural networks efficiently with high-level TensorFlow APIs\n",
    "\n",
    "### Building multilayer neural networks using TensorFlow's Layers API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzips mnist\n",
    "\n",
    "import sys\n",
    "import gzip\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "if (sys.version_info > (3,0)):\n",
    "    writemode = 'wb'\n",
    "else:\n",
    "    writemode = 'w'\n",
    "    \n",
    "zipped_mnist = [f for f in os.listdir('./') if f.endswith('ubyte.gz')]\n",
    "\n",
    "for z in zipped_mnist:\n",
    "    with gzip.GzipFile(z, mode = 'rb') as decompressed, open(z[:-3], writemode) as outfile:\n",
    "        outfile.write(decompressed.read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "\n",
    "def load_mnist(path,kind='train'):\n",
    "    \"\"\"Load MNIST data from `path`\"\"\"\n",
    "    labels_path = os.path.join(path, '%s-labels-idx1-ubyte' % kind)\n",
    "    images_path = os.path.join(path, '%s-images-idx3-ubyte' % kind)\n",
    "    \n",
    "    with open(labels_path, 'rb') as lbpath:\n",
    "        magic, n = struct.unpack('>II', lbpath.read(8))\n",
    "        labels = np.fromfile(lbpath, dtype = np.uint8)\n",
    "        \n",
    "    with open(images_path, 'rb') as imgpath:\n",
    "        magic, num, rows, cols = struct.unpack('>IIII', imgpath.read(16))\n",
    "        images = np.fromfile(imgpath,dtype = np.uint8).reshape(len(labels),784)\n",
    "        images = ( ( images / 255. ) - .5 ) * 2\n",
    "    \n",
    "    return images, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 60000, Columns: 784\n",
      "Rows: 10000, Columns: 784\n",
      "(60000, 784) (60000,)\n",
      "(10000, 784) (10000,)\n"
     ]
    }
   ],
   "source": [
    "## loading the data\n",
    "\n",
    "X_train, y_train = load_mnist('.', kind = 'train')\n",
    "print('Rows: %d, Columns: %d' % (X_train.shape[0],\n",
    "                                 X_train.shape[1]))\n",
    "\n",
    "X_test, y_test = load_mnist('.', kind = 't10k')\n",
    "print('Rows: %d, Columns: %d' % (X_test.shape[0],\n",
    "                                 X_test.shape[1]))\n",
    "\n",
    "## mean centering and normalization\n",
    "mean_vals = np.mean(X_train, axis = 0)\n",
    "std_val = np.std(X_train)\n",
    "\n",
    "X_train_centered = (X_train - mean_vals)/std_val\n",
    "X_test_centered = (X_test - mean_vals)/std_val # assume the test data are from the training set\n",
    "\n",
    "del X_train, X_test\n",
    "\n",
    "print(X_train_centered.shape, y_train.shape)\n",
    "\n",
    "print(X_test_centered.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "n_features = X_train_centered.shape[1]\n",
    "n_classes = 10\n",
    "random_seed = 123\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "g = tf.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "    tf.set_random_seed(random_seed)\n",
    "    tf_x = tf.placeholder(dtype = tf.float32,\n",
    "                          shape = (None, n_features),\n",
    "                          name = 'tf_x')\n",
    "    tf_y = tf.placeholder(dtype = tf.int32,\n",
    "                          shape = None, name = 'tf_y')\n",
    "    y_onehot = tf.one_hot(indices = tf_y, depth = n_classes)\n",
    "    \n",
    "    h1 = tf.layers.dense(inputs = tf_x, units = 50,\n",
    "                         activation = tf.tanh,\n",
    "                         name = 'layer1')\n",
    "    \n",
    "    h2 = tf.layers.dense(inputs = h1, units = 50,\n",
    "                         activation = tf.tanh,\n",
    "                         name = 'layer2')\n",
    "    \n",
    "    logits = tf.layers.dense(inputs = h2,\n",
    "                             units = 10,\n",
    "                             activation = None,\n",
    "                             name = 'layer3')\n",
    "    \n",
    "    predictions = {\n",
    "        'classes' : tf.argmax(logits, axis = 1,\n",
    "                              name = 'predicted_classes'),\n",
    "        'probabilities' : tf.nn.softmax(logits,\n",
    "                                        name = 'softmax_tensor')\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/Rex/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/losses/losses_impl.py:691: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## define cost function and optimizer:\n",
    "\n",
    "with g.as_default():\n",
    "    cost = tf.losses.softmax_cross_entropy(onehot_labels = y_onehot,\n",
    "                                           logits = logits)\n",
    "    \n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "    \n",
    "    train_op = optimizer.minimize(loss = cost)\n",
    "    \n",
    "    init_op = tf.global_variables_initializer()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate batches of data\n",
    "\n",
    "def create_batch_generator(X, y, batch_size = 128, shuffle = False):\n",
    "    X_copy = np.array(X)\n",
    "    y_copy = np.array(y)\n",
    "    \n",
    "    if shuffle:\n",
    "        data = np.column_stack((X_copy, y_copy))\n",
    "        np.random.shuffle(data)\n",
    "        X_copy = data[:, :-1]\n",
    "        y_copy = data[:,-1].astype(int)\n",
    "    \n",
    "    for i in range(0, X.shape[0], batch_size):\n",
    "        yield (X_copy[i:i+batch_size,:], y_copy[i:i+batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -- Epoch  1  Avg. Training Loss: 1.5573\n",
      " -- Epoch  2  Avg. Training Loss: 1.2532\n",
      " -- Epoch  3  Avg. Training Loss: 1.0854\n",
      " -- Epoch  4  Avg. Training Loss: 0.9738\n",
      " -- Epoch  5  Avg. Training Loss: 0.8924\n",
      " -- Epoch  6  Avg. Training Loss: 0.8296\n",
      " -- Epoch  7  Avg. Training Loss: 0.7794\n",
      " -- Epoch  8  Avg. Training Loss: 0.7381\n",
      " -- Epoch  9  Avg. Training Loss: 0.7032\n",
      " -- Epoch 10  Avg. Training Loss: 0.6734\n",
      " -- Epoch 11  Avg. Training Loss: 0.6475\n",
      " -- Epoch 12  Avg. Training Loss: 0.6247\n",
      " -- Epoch 13  Avg. Training Loss: 0.6045\n",
      " -- Epoch 14  Avg. Training Loss: 0.5864\n",
      " -- Epoch 15  Avg. Training Loss: 0.5700\n",
      " -- Epoch 16  Avg. Training Loss: 0.5551\n",
      " -- Epoch 17  Avg. Training Loss: 0.5415\n",
      " -- Epoch 18  Avg. Training Loss: 0.5290\n",
      " -- Epoch 19  Avg. Training Loss: 0.5175\n",
      " -- Epoch 20  Avg. Training Loss: 0.5068\n",
      " -- Epoch 21  Avg. Training Loss: 0.4968\n",
      " -- Epoch 22  Avg. Training Loss: 0.4875\n",
      " -- Epoch 23  Avg. Training Loss: 0.4788\n",
      " -- Epoch 24  Avg. Training Loss: 0.4706\n",
      " -- Epoch 25  Avg. Training Loss: 0.4629\n",
      " -- Epoch 26  Avg. Training Loss: 0.4556\n",
      " -- Epoch 27  Avg. Training Loss: 0.4487\n",
      " -- Epoch 28  Avg. Training Loss: 0.4422\n",
      " -- Epoch 29  Avg. Training Loss: 0.4359\n",
      " -- Epoch 30  Avg. Training Loss: 0.4300\n",
      " -- Epoch 31  Avg. Training Loss: 0.4243\n",
      " -- Epoch 32  Avg. Training Loss: 0.4189\n",
      " -- Epoch 33  Avg. Training Loss: 0.4138\n",
      " -- Epoch 34  Avg. Training Loss: 0.4088\n",
      " -- Epoch 35  Avg. Training Loss: 0.4041\n",
      " -- Epoch 36  Avg. Training Loss: 0.3995\n",
      " -- Epoch 37  Avg. Training Loss: 0.3951\n",
      " -- Epoch 38  Avg. Training Loss: 0.3909\n",
      " -- Epoch 39  Avg. Training Loss: 0.3868\n",
      " -- Epoch 40  Avg. Training Loss: 0.3829\n",
      " -- Epoch 41  Avg. Training Loss: 0.3791\n",
      " -- Epoch 42  Avg. Training Loss: 0.3754\n",
      " -- Epoch 43  Avg. Training Loss: 0.3718\n",
      " -- Epoch 44  Avg. Training Loss: 0.3684\n",
      " -- Epoch 45  Avg. Training Loss: 0.3651\n",
      " -- Epoch 46  Avg. Training Loss: 0.3618\n",
      " -- Epoch 47  Avg. Training Loss: 0.3587\n",
      " -- Epoch 48  Avg. Training Loss: 0.3556\n",
      " -- Epoch 49  Avg. Training Loss: 0.3527\n",
      " -- Epoch 50  Avg. Training Loss: 0.3498\n"
     ]
    }
   ],
   "source": [
    "## create a session to launch the graph\n",
    "sess = tf.Session(graph=g)\n",
    "## run the variable initialization operator\n",
    "sess.run(init_op)\n",
    "\n",
    "# 50 epochs of training:\n",
    "\n",
    "training_costs = []\n",
    "\n",
    "for epoch in range(50):\n",
    "    batch_generator = create_batch_generator(X_train_centered,\n",
    "                                             y_train,\n",
    "                                             batch_size = 64)\n",
    "    for batch_X, batch_y in batch_generator:\n",
    "        ##prepare a dict to feed data to our network:\n",
    "        feed = {tf_x: batch_X, tf_y: batch_y}\n",
    "        _, batch_cost = sess.run([train_op, cost],\n",
    "                                 feed_dict = feed)\n",
    "        training_costs.append(batch_cost)\n",
    "    print(' -- Epoch %2d  '\n",
    "          'Avg. Training Loss: %.4f' % (epoch+1, np.mean(training_costs)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 93.89%\n"
     ]
    }
   ],
   "source": [
    "# do prediction on the test set\n",
    "\n",
    "feed = {tf_x : X_test_centered}\n",
    "y_pred = sess.run(predictions['classes'],\n",
    "                  feed_dict = feed)\n",
    "print('Test Accuracy: %.2f%%' % (100*np.sum(y_pred == y_test)/y_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Developing Multilayer Neural Networks with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 60000, Columns: 784\n",
      "Rows: 10000, Columns: 784\n",
      "(60000, 784) (60000,)\n",
      "(10000, 784) (10000,)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = load_mnist('./', kind = 'train')\n",
    "print('Rows: %d, Columns: %d' %(X_train.shape[0],\n",
    "                                X_train.shape[1]))\n",
    "X_test, y_test = load_mnist('./', kind = 't10k')\n",
    "print('Rows: %d, Columns: %d' %(X_test.shape[0],\n",
    "                                X_test.shape[1]))\n",
    "\n",
    "## Mean centering and normalization:\n",
    "mean_vals = np.mean(X_train, axis = 0)\n",
    "std_val = np.std(X_train)\n",
    "\n",
    "X_train_centered = (X_train - mean_vals)/std_val\n",
    "X_test_centered = (X_test - mean_vals)/std_val\n",
    "\n",
    "del X_train, X_test\n",
    "\n",
    "print(X_train_centered.shape, y_train.shape)\n",
    "print(X_test_centered.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 3 labels:  [5 0 4]\n",
      "\n",
      "First 3 labels (one-hot):\n",
      " [[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "np.random.seed(123)\n",
    "tf.set_random_seed(123)\n",
    "y_train_onehot = tf.keras.utils.to_categorical(y_train)\n",
    "print('First 3 labels: ', y_train[:3])\n",
    "print('\\nFirst 3 labels (one-hot):\\n', y_train_onehot[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/Rex/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/backend.py:3086: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/Rex/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/backend.py:1557: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/50\n",
      "54000/54000 [==============================]54000/54000 [==============================] - 7s 127us/step - loss: 0.7247 - val_loss: 0.3616\n",
      "\n",
      "Epoch 2/50\n",
      "54000/54000 [==============================]54000/54000 [==============================] - 6s 104us/step - loss: 0.3718 - val_loss: 0.2815\n",
      "\n",
      "Epoch 3/50\n",
      "54000/54000 [==============================]54000/54000 [==============================] - 7s 133us/step - loss: 0.3087 - val_loss: 0.2447\n",
      "\n",
      "Epoch 4/50\n",
      "54000/54000 [==============================]54000/54000 [==============================] - 7s 125us/step - loss: 0.2728 - val_loss: 0.2216\n",
      "\n",
      "Epoch 5/50\n",
      "54000/54000 [==============================]54000/54000 [==============================] - 8s 145us/step - loss: 0.2475 - val_loss: 0.2042\n",
      "\n",
      "Epoch 6/50\n",
      "54000/54000 [==============================]54000/54000 [==============================] - 5s 99us/step - loss: 0.2277 - val_loss: 0.1918\n",
      "\n",
      "Epoch 7/50\n",
      "54000/54000 [==============================]54000/54000 [==============================] - 6s 111us/step - loss: 0.2115 - val_loss: 0.1810\n",
      "\n",
      "Epoch 8/50\n",
      "54000/54000 [==============================]54000/54000 [==============================] - 5s 91us/step - loss: 0.1979 - val_loss: 0.1719\n",
      "\n",
      "Epoch 9/50\n",
      "54000/54000 [==============================]54000/54000 [==============================] - 6s 116us/step - loss: 0.1860 - val_loss: 0.1646\n",
      "\n",
      "Epoch 10/50\n",
      "54000/54000 [==============================]54000/54000 [==============================] - 6s 104us/step - loss: 0.1758 - val_loss: 0.1591\n",
      "\n",
      "Epoch 11/50\n",
      "54000/54000 [==============================]54000/54000 [==============================] - 6s 114us/step - loss: 0.1667 - val_loss: 0.1543\n",
      "\n",
      "Epoch 12/50\n",
      "54000/54000 [==============================]54000/54000 [==============================] - 5s 84us/step - loss: 0.1589 - val_loss: 0.1492\n",
      "\n",
      "Epoch 13/50\n",
      "54000/54000 [==============================]54000/54000 [==============================] - 5s 97us/step - loss: 0.1516 - val_loss: 0.1451\n",
      "\n",
      "Epoch 14/50\n",
      "54000/54000 [==============================]54000/54000 [==============================] - 6s 105us/step - loss: 0.1450 - val_loss: 0.1420\n",
      "\n",
      "Epoch 15/50\n",
      "54000/54000 [==============================]54000/54000 [==============================] - 6s 114us/step - loss: 0.1389 - val_loss: 0.1386\n",
      "\n",
      "Epoch 16/50\n",
      "54000/54000 [==============================]54000/54000 [==============================] - 5s 91us/step - loss: 0.1333 - val_loss: 0.1363\n",
      "\n",
      "Epoch 17/50\n",
      "54000/54000 [==============================]54000/54000 [==============================] - 6s 119us/step - loss: 0.1283 - val_loss: 0.1332\n",
      "\n",
      "Epoch 18/50\n",
      "54000/54000 [==============================]54000/54000 [==============================] - 5s 88us/step - loss: 0.1234 - val_loss: 0.1327\n",
      "\n",
      "Epoch 19/50\n",
      "54000/54000 [==============================]54000/54000 [==============================] - 6s 102us/step - loss: 0.1191 - val_loss: 0.1293\n",
      "\n",
      "Epoch 20/50\n",
      "54000/54000 [==============================]54000/54000 [==============================] - 6s 112us/step - loss: 0.1148 - val_loss: 0.1282\n",
      "\n",
      "Epoch 21/50\n",
      "54000/54000 [==============================]54000/54000 [==============================] - 8s 142us/step - loss: 0.1109 - val_loss: 0.1271\n",
      "\n",
      "Epoch 22/50\n",
      "54000/54000 [==============================]54000/54000 [==============================] - 6s 115us/step - loss: 0.1071 - val_loss: 0.1265\n",
      "\n",
      "Epoch 23/50\n",
      "54000/54000 [==============================]54000/54000 [==============================] - 6s 120us/step - loss: 0.1037 - val_loss: 0.1243\n",
      "\n",
      "Epoch 24/50\n",
      "54000/54000 [==============================]54000/54000 [==============================] - 7s 120us/step - loss: 0.1003 - val_loss: 0.1229\n",
      "\n",
      "Epoch 25/50\n",
      "54000/54000 [==============================]54000/54000 [==============================] - 5s 99us/step - loss: 0.0971 - val_loss: 0.1217\n",
      "\n",
      "Epoch 26/50\n",
      "54000/54000 [==============================]54000/54000 [==============================] - 6s 118us/step - loss: 0.0941 - val_loss: 0.1212\n",
      "\n",
      "Epoch 27/50\n",
      "54000/54000 [==============================]54000/54000 [==============================] - 8s 145us/step - loss: 0.0912 - val_loss: 0.1200\n",
      "\n",
      "Epoch 28/50\n",
      "54000/54000 [==============================]54000/54000 [==============================] - 7s 124us/step - loss: 0.0884 - val_loss: 0.1202\n",
      "\n",
      "Epoch 29/50\n",
      "54000/54000 [==============================]54000/54000 [==============================] - 7s 131us/step - loss: 0.0858 - val_loss: 0.1189\n",
      "\n",
      "Epoch 30/50\n",
      "54000/54000 [==============================]54000/54000 [==============================] - 7s 122us/step - loss: 0.0834 - val_loss: 0.1184\n",
      "\n",
      "Epoch 31/50\n",
      "54000/54000 [==============================]54000/54000 [==============================] - 5s 99us/step - loss: 0.0810 - val_loss: 0.1184\n",
      "\n",
      "Epoch 32/50\n",
      "54000/54000 [==============================]54000/54000 [==============================] - 6s 117us/step - loss: 0.0787 - val_loss: 0.1189\n",
      "\n",
      "Epoch 33/50\n",
      "54000/54000 [==============================]54000/54000 [==============================] - 6s 106us/step - loss: 0.0765 - val_loss: 0.1183\n",
      "\n",
      "Epoch 34/50\n",
      "54000/54000 [==============================]54000/54000 [==============================] - 6s 119us/step - loss: 0.0743 - val_loss: 0.1197\n",
      "\n",
      "Epoch 35/50\n",
      "54000/54000 [==============================]54000/54000 [==============================] - 5s 99us/step - loss: 0.0723 - val_loss: 0.1179\n",
      "\n",
      "Epoch 36/50\n",
      "54000/54000 [==============================]54000/54000 [==============================] - 5s 101us/step - loss: 0.0703 - val_loss: 0.1174\n",
      "\n",
      "Epoch 37/50\n",
      "54000/54000 [==============================]54000/54000 [==============================] - 6s 107us/step - loss: 0.0684 - val_loss: 0.1185\n",
      "\n",
      "Epoch 38/50\n",
      "54000/54000 [==============================]54000/54000 [==============================] - 6s 105us/step - loss: 0.0665 - val_loss: 0.1187\n",
      "\n",
      "Epoch 39/50\n",
      "54000/54000 [==============================]54000/54000 [==============================] - 6s 107us/step - loss: 0.0647 - val_loss: 0.1172\n",
      "\n",
      "Epoch 40/50\n",
      "54000/54000 [==============================]54000/54000 [==============================] - 6s 105us/step - loss: 0.0629 - val_loss: 0.1172\n",
      "\n",
      "Epoch 41/50\n",
      "54000/54000 [==============================]54000/54000 [==============================] - 6s 104us/step - loss: 0.0613 - val_loss: 0.1175\n",
      "\n",
      "Epoch 42/50\n",
      "54000/54000 [==============================]54000/54000 [==============================] - 6s 110us/step - loss: 0.0597 - val_loss: 0.1171\n",
      "\n",
      "Epoch 43/50\n",
      "54000/54000 [==============================]54000/54000 [==============================] - 5s 98us/step - loss: 0.0581 - val_loss: 0.1168\n",
      "\n",
      "Epoch 44/50\n",
      "54000/54000 [==============================]54000/54000 [==============================] - 6s 104us/step - loss: 0.0566 - val_loss: 0.1166\n",
      "\n",
      "Epoch 45/50\n",
      "54000/54000 [==============================]54000/54000 [==============================] - 7s 129us/step - loss: 0.0552 - val_loss: 0.1166\n",
      "\n",
      "Epoch 46/50\n",
      "54000/54000 [==============================]54000/54000 [==============================] - 7s 124us/step - loss: 0.0537 - val_loss: 0.1162\n",
      "\n",
      "Epoch 47/50\n",
      "54000/54000 [==============================]54000/54000 [==============================] - 6s 114us/step - loss: 0.0523 - val_loss: 0.1170\n",
      "\n",
      "Epoch 48/50\n",
      "54000/54000 [==============================]54000/54000 [==============================] - 7s 134us/step - loss: 0.0510 - val_loss: 0.1172\n",
      "\n",
      "Epoch 49/50\n",
      "54000/54000 [==============================]54000/54000 [==============================] - 7s 128us/step - loss: 0.0498 - val_loss: 0.1171\n",
      "\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54000/54000 [==============================]54000/54000 [==============================] - 6s 102us/step - loss: 0.0485 - val_loss: 0.1174\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(\n",
    "    tf.keras.layers.Dense(\n",
    "        units = 50, \n",
    "        input_dim = X_train_centered.shape[1],# first layer, `input_dim` matches the # of features\n",
    "        kernel_initializer = 'glorot_uniform',\n",
    "        bias_initializer = 'zeros',\n",
    "        activation = 'tanh'))\n",
    "\n",
    "model.add(\n",
    "    tf.keras.layers.Dense(\n",
    "        units = 50,\n",
    "        input_dim = 50, # # of output units and input units of two consecutive layers match\n",
    "        kernel_initializer = 'glorot_uniform',\n",
    "        bias_initializer = 'zeros',\n",
    "        activation = 'tanh'))\n",
    "model.add(\n",
    "    tf.keras.layers.Dense(\n",
    "        units = y_train_onehot.shape[1],\n",
    "        input_dim = 50,\n",
    "        kernel_initializer = 'glorot_uniform',\n",
    "        bias_initializer = 'zeros',\n",
    "        activation = 'softmax'))\n",
    "\n",
    "sgd_optimizer = tf.keras.optimizers.SGD(\n",
    "    lr = 0.001, decay = 1e-7, momentum = .9)\n",
    "\n",
    "model.compile(optimizer = sgd_optimizer,\n",
    "                loss = 'categorical_crossentropy')\n",
    "\n",
    "history = model.fit(X_train_centered, y_train_onehot,\n",
    "                    batch_size = 64, epochs = 50,\n",
    "                    verbose = 1,\n",
    "                    validation_split = 0.1) # reserve 10% training data for validation, monitor whether overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 3 predictions:  [5 0 4]\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = model.predict_classes(X_train_centered, verbose = 0)\n",
    "print('First 3 predictions: ', y_train_pred[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 3 predictions:  [5 0 4]\n",
      "Training accuracy: 98.88%\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = model.predict_classes(X_train_centered,\n",
    "                                     verbose = 0)\n",
    "correct_preds = np.sum(y_train == y_train_pred, axis = 0)\n",
    "\n",
    "train_acc = correct_preds / y_train.shape[0]\n",
    "\n",
    "print('First 3 predictions: ', y_train_pred[:3])\n",
    "print('Training accuracy: %.2f%%' % (train_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 96.04%\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = model.predict_classes(X_test_centered,\n",
    "                                    verbose = 0)\n",
    "correct_preds = np.sum(y_test == y_test_pred, axis = 0)\n",
    "test_acc = correct_preds / y_test.shape[0]\n",
    "print('Test accuracy: %.2f%%' % (test_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing activation functions for multilayer networks\n",
    "\n",
    "### Logistic function recap\n",
    "\n",
    "- introduce nonlinearity in a typical artificial neural network to be able to tackle complex problems\n",
    "\n",
    "- but logistic activation functions can be problematic if we have highly negative input since the output of the sigmoid function would be close to zero in this case\n",
    "    - neural network would learn very slowly\n",
    "    - trapped in the local minimal\n",
    "    - prefer a hyperbolic tangent as an activation function in hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(y=1|x) = 0.888, meaning 88.8% probability that this particular sample x belongs to the positive class\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([1, 1.4, 2.5]) ## first value must be 1\n",
    "w = np.array([0.4, 0.3, 0.5])\n",
    "\n",
    "def net_input(X, w):\n",
    "    return np.dot(X,w)\n",
    "\n",
    "def logistic(z):\n",
    "    return 1.0/(1.0 + np.exp(-z))\n",
    "\n",
    "def logistic_activation(X, w):\n",
    "    z = net_input(X, w)\n",
    "    return logistic(z)\n",
    "\n",
    "print('P(y=1|x) = %.3f, meaning 88.8%% probability that this particular sample x belongs to the positive class' % logistic_activation(X,w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, an output layer consisting of multiple logistic activation units does not produce meaningful, interpretable probability values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net Input: \n",
      " [1.78 0.76 1.65]\n",
      "Output Units:\n",
      " [0.85569687 0.68135373 0.83889105]\n"
     ]
    }
   ],
   "source": [
    "# W : array with shape = (n_output_units, n_hidden_units+1)\n",
    "#     note that the first column are the bias units\n",
    "\n",
    "W = np.array([[1.1, 1.2, 0.8, 0.4],\n",
    "              [0.2, 0.4, 1.0, 0.2],\n",
    "              [0.6, 1.5, 1.2, 0.7]])\n",
    "\n",
    "# A : data array with shape = (n_hidden_units + 1, n_samples)\n",
    "#     note that the first column of this array must be 1\n",
    "\n",
    "A = np.array([[1, 0.1, 0.4, 0.6]])\n",
    "\n",
    "Z = np.dot(W, A[0])\n",
    "y_probas = logistic(Z)\n",
    "\n",
    "print('Net Input: \\n', Z)\n",
    "\n",
    "print('Output Units:\\n', y_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though it is not a big concern if we only use our model to predict the class lbels, not the class membership probabilities,\n",
    "the easiest way is to use the maximum value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class label: 0\n"
     ]
    }
   ],
   "source": [
    "y_class = np.argmax(Z, axis = 0)\n",
    "print('Predicted class label: %d' % y_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating class probabilities in multi-class classification via the softmax function\n",
    "\n",
    "- instead of giving a single class index, it provides the probability of each class\n",
    "\n",
    "- the sum of all M linear fucntion = normalization term in the denominator\n",
    "\n",
    "- the predicted class probabilities sum up to 1\n",
    "\n",
    "    - In a word, `softmax` is a normalized `logistic`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities: \n",
      " [0.44668973 0.16107406 0.39223621]\n"
     ]
    }
   ],
   "source": [
    "def softmax(z):\n",
    "    return np.exp(z)/np.sum(np.exp(z))\n",
    "\n",
    "y_probas = softmax(Z)\n",
    "print('Probabilities: \\n', y_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadening the output spectrum by using a hyperbolic tangent\n",
    "\n",
    "- hyperbolic tangent (tanh)\n",
    "- rescaled version of the logistic function\n",
    "- adv: \n",
    "    - broader output spectrum, \n",
    "    - ranges in the open interval(-1,1)\n",
    "        - improve the convergence of the back propagation algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def tanh(z):\n",
    "    e_p = np.exp(z)\n",
    "    e_m = np.exp(-z)\n",
    "    return (e_p - e_m) / (e_p + e_m)\n",
    "\n",
    "z = np.arange(-5, 5, 0.005)\n",
    "log_act = logistic(z)\n",
    "tanh_act = tanh(z)\n",
    "\n",
    "plt.ylim([-1.5, 1.5])\n",
    "plt.xlabel('net input $z$')\n",
    "plt.ylabel('activation $\\phi(z)$')\n",
    "plt.axhline(1, color='black', linestyle=':')\n",
    "plt.axhline(0.5, color='black', linestyle=':')\n",
    "plt.axhline(0, color='black', linestyle=':')\n",
    "plt.axhline(-0.5, color='black', linestyle=':')\n",
    "plt.axhline(-1, color='black', linestyle=':')\n",
    "\n",
    "plt.plot(z, tanh_act,\n",
    "         linewidth=3, linestyle='--',\n",
    "         label='tanh')\n",
    "\n",
    "plt.plot(z, log_act,\n",
    "         linewidth=3,\n",
    "         label='logistic')\n",
    "plt.legend(loc='lower right')\n",
    "plt.tight_layout()\n",
    "#plt.savefig('images/13_03.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
